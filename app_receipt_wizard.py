# -*- coding: utf-8 -*-
"""
Receipt OCR â†’ LLM Review UI (Streamlit Wizard)
- ìƒë‹¨ íƒ­: Upload / Extract / Review / Journal Entry / Visual Verify / Export
- ì¢Œì¸¡: ì§„í–‰/í, ìš°ì¸¡: ê° íƒ­ ë³¸ë¬¸
"""

import io
import os
import json
import time
import zipfile
import shutil
import tempfile
from typing import Dict, Any, List, Tuple, Optional
from dataclasses import dataclass

import pandas as pd
import streamlit as st
from PIL import Image

# ==== í”„ë¡œì íŠ¸ ë‚´ë¶€ ìœ í‹¸ (ê²½ë¡œëŠ” í”„ë¡œì íŠ¸ êµ¬ì¡°ì— ë§ì¶° ìˆ˜ì •í•˜ì„¸ìš”) ====
# LLM ì¶”ì¶œ + ìœ„ì¹˜ ë§¤ì¹­ + ì‹œê°í™” ìœ í‹¸
from src.ant.llm_main import (
    extract_with_locations,
    draw_overlays,
    export_thumbnails,
)
# OCR: ì´ë¯¸ êµ¬í˜„ë¨
# from your_ocr_module import ocr_image_and_save_json_by_extension
from src.entocr.ocr_main import ocr_image_and_save_json_by_extension
# (ì„ íƒ) ì¹´í…Œê³ ë¦¬/ë¶„ê°œ ë§¤í•‘ì— í™œìš©
try:
    from src.ant.constants import CATEGORY
except Exception:
    CATEGORY = []

# ========================= ê¸°ë³¸ ì„¤ì • =========================
st.set_page_config(page_title="AutoVoucher AI", page_icon="ğŸ§¾", layout="wide")
st.title("ğŸ§¾ AutoVoucher AI")

# ========================= ìƒíƒœ ì´ˆê¸°í™” =========================
def _init_state():
    ss = st.session_state
    ss.setdefault("workdir", tempfile.mkdtemp(prefix="st_wizard_"))
    ss.setdefault("images", [])            # ì—…ë¡œë“œëœ ì´ë¯¸ì§€ ê²½ë¡œë“¤
    ss.setdefault("queue", [])             # ì²˜ë¦¬ ëŒ€ê¸° í (ì´ë¯¸ì§€ ê²½ë¡œ)
    ss.setdefault("results", {})           # {img_path: {"data","candidates","selections","ocr_json"}}
    ss.setdefault("overlay_paths", {})     # {img_path: overlay.png}
    ss.setdefault("thumb_dirs", {})        # {img_path: dir}
    ss.setdefault("logs", [])              # ì „ì²´ ë¡œê·¸
    ss.setdefault("errors", {})            # {img_path: "ì—ëŸ¬ë©”ì‹œì§€"}
    ss.setdefault("model_name", "gpt4o_latest")
    ss.setdefault("lang", "kor+eng")
    ss.setdefault("deskew", False)
    ss.setdefault("denoise", False)
    ss.setdefault("vat_rate", 0.1)         # ë¶„ê°œìš© VAT ê°€ì • (í•„ìš”ì‹œ í¸ì§‘)
    ss.setdefault("mapping_profile", "Default")
    ss.setdefault("je_rows_cache", None)   # ë¶„ê°œ ë¯¸ë¦¬ë³´ê¸° DataFrame
    ss.setdefault("review_df_cache", None) # ë¦¬ë·° í…Œì´ë¸” DataFrame
    ss.setdefault("selected_file_for_visual", None)
    ss.setdefault("selected_fields_for_visual", [])  # e.g. ["ê±°ë˜ì²˜","ê¸ˆì•¡"]
_init_state()

# ========================= ê³µí†µ ìœ í‹¸ =========================
def _is_image(path_or_name: str) -> bool:
    return path_or_name.lower().endswith((".png",".jpg",".jpeg",".webp",".bmp",".tif",".tiff"))

def _save_uploaded_files(files: List) -> List[str]:
    """Streamlit ì—…ë¡œë”ë¡œ ë°›ì€ íŒŒì¼ë“¤ì„ ì„ì‹œ í´ë”ì— ì €ì¥"""
    paths = []
    save_dir = os.path.join(st.session_state["workdir"], "uploads")
    os.makedirs(save_dir, exist_ok=True)
    for f in files:
        dest = os.path.join(save_dir, f.name)
        with open(dest, "wb") as out:
            out.write(f.read())
        paths.append(dest)
    return paths

def _extract_zip(file_bytes: bytes) -> List[str]:
    """ZIPì—ì„œ ì´ë¯¸ì§€ ì¶”ì¶œ"""
    save_dir = os.path.join(st.session_state["workdir"], "uploads_zip")
    os.makedirs(save_dir, exist_ok=True)
    paths = []
    with zipfile.ZipFile(io.BytesIO(file_bytes)) as z:
        for n in z.namelist():
            if n.endswith("/"): 
                continue
            if not _is_image(n): 
                continue
            fname = os.path.basename(n)
            dest = os.path.join(save_dir, fname)
            with z.open(n) as src, open(dest, "wb") as dst:
                shutil.copyfileobj(src, dst)
            paths.append(dest)
    return sorted(paths)

def _log(msg: str):
    st.session_state["logs"].append(f"[{time.strftime('%H:%M:%S')}] {msg}")

def _queue_images(paths: List[str]):
    ss = st.session_state
    for p in paths:
        if p not in ss["images"]:
            ss["images"].append(p)
        if p not in ss["queue"] and p not in ss["results"]:
            ss["queue"].append(p)

def _short(s: str, n: int = 18) -> str:
    s = str(s)
    return s if len(s) <= n else s[:n] + "â€¦"

def _first_val(obj_list: List[Dict[str, Any]]) -> str:
    """[{"value":..., "source_id":...}] ì¤‘ ì²« valueë§Œ ë°˜í™˜(ì—†ìœ¼ë©´ ë¹ˆë¬¸ìì—´)"""
    if isinstance(obj_list, list) and obj_list:
        return str(obj_list[0].get("value",""))
    return ""

def _to_number(s: str) -> Optional[float]:
    try:
        return float(str(s).replace(",", "").strip())
    except Exception:
        return None

# ========================= Upload íƒ­ =========================
def tab_upload():
    left, right = st.columns([1,2], gap="large")

    with left:
        st.subheader("ì§„í–‰/í")
        total = len(st.session_state["images"])
        done = len(st.session_state["results"])
        waiting = len(st.session_state["queue"])
        st.metric("ì´ ì´ë¯¸ì§€", total)
        st.metric("ì™„ë£Œ", done)
        st.metric("ëŒ€ê¸°", waiting)
        if st.session_state["errors"]:
            st.error(f"ì‹¤íŒ¨ {len(st.session_state['errors'])}ê±´")

        # st.divider()
        # st.subheader("ì˜µì…˜")
        # st.session_state["model_name"] = st.text_input("LLM ëª¨ë¸", st.session_state["model_name"])
        # st.session_state["lang"] = st.selectbox("OCR ì–¸ì–´(ì°¸ê³ ìš©)", ["kor", "eng", "kor+eng"], index=2)
        # st.session_state["deskew"] = st.checkbox("ì „ì²˜ë¦¬: Deskew", value=st.session_state["deskew"])
        # st.session_state["denoise"] = st.checkbox("ì „ì²˜ë¦¬: Denoise", value=st.session_state["denoise"])

        # st.info("â€» ì „ì²˜ë¦¬ ì˜µì…˜ì€ ì‹¤ì œ OCR í•¨ìˆ˜ êµ¬í˜„ì— ë°˜ì˜ë˜ì–´ì•¼ í•©ë‹ˆë‹¤. í˜„ì¬ í™”ë©´ì€ ì˜µì…˜ ì „ë‹¬ë§Œ í•©ë‹ˆë‹¤.")

    with right:
        st.subheader("1) ì´ë¯¸ì§€ ì—…ë¡œë“œ")
        imgs = st.file_uploader("ì—¬ëŸ¬ ì´ë¯¸ì§€ ì„ íƒ", accept_multiple_files=True, type=["pdf","png","jpg","jpeg","webp","tif","tiff","bmp"])
        # zf = st.file_uploader("ë˜ëŠ” ZIP ì—…ë¡œë“œ", type=["zip"])

        colx, coly = st.columns([1,1])
        with colx:
            if st.button("ì´ë¯¸ì§€ ì¶”ê°€"):
                if imgs:
                    paths = _save_uploaded_files(imgs)
                    _queue_images(paths)
                    _log(f"ì´ë¯¸ì§€ {len(paths)}ê±´ ë“±ë¡")
                    st.success("ëŒ€ê¸° ì‘ì—…ì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤. ìƒë‹¨ íƒ­ì—ì„œ **2. Extract**ë¥¼ í´ë¦­í•´ ì²˜ë¦¬í•˜ì„¸ìš”.")

                else:
                    st.warning("ì´ë¯¸ì§€ë¥¼ ì„ íƒí•˜ì„¸ìš”.")
        # with coly:
        #     if st.button("ZIP ì¶”ì¶œ"):
        #         if zf:
        #             paths = _extract_zip(zf.getvalue())
        #             _queue_images(paths)
        #             _log(f"ZIPì—ì„œ ì´ë¯¸ì§€ {len(paths)}ê±´ ì¶”ì¶œ")
        #         else:
        #             st.warning("ZIP íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")

        st.markdown("#### ì—…ë¡œë“œ ëª©ë¡")
        if st.session_state["images"]:
            df = pd.DataFrame({
                "file": [os.path.basename(p) for p in st.session_state["images"]],
                "path": st.session_state["images"],
                "status": ["âœ…" if p in st.session_state["results"] else ("â³" if p in st.session_state["queue"] else "â€¢") for p in st.session_state["images"]],
            })
            st.dataframe(df, use_container_width=True, hide_index=True, height=320)
        else:
            st.info("ì—…ë¡œë“œëœ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")

        # st.divider()
        # if st.button("ì‹œì‘(Start)", type="primary"):
        #     # ëŒ€ê¸° í êµ¬ì„±
        #     for p in st.session_state["images"]:
        #         if p not in st.session_state["results"] and p not in st.session_state["queue"]:
        #             st.session_state["queue"].append(p)

        #     st.success("ëŒ€ê¸° ì‘ì—…ì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤. ìƒë‹¨ íƒ­ì—ì„œ **2. Extract**ë¥¼ í´ë¦­í•´ ì²˜ë¦¬í•˜ì„¸ìš”.")
        #     st.toast("ëŒ€ê¸° í ì¤€ë¹„ ì™„ë£Œ â†’ Extract íƒ­ìœ¼ë¡œ ì´ë™í•´ ì£¼ì„¸ìš”.")
            # ìƒˆë¡œê³ ì¹¨ìœ¼ë¡œ ì¢Œì¸¡ â€˜ëŒ€ê¸°â€™ ì¹´ìš´í„°ë§Œ ì—…ë°ì´íŠ¸í•˜ê³  íƒ­ ì „í™˜ì€ í•˜ì§€ ì•ŠìŒ
            # st.rerun()

# ========================= Extract íƒ­ =========================
def _process_queue():
    ss = st.session_state
    q = ss["queue"][:]
    n = len(q)
    if not n:
        st.info("ëŒ€ê¸° ì¤‘ì¸ ì‘ì—…ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    prog = st.progress(0.0, text="ì²˜ë¦¬ ì‹œì‘")

    for i, img_path in enumerate(q, 1):
        # try:
        _log(f"[{os.path.basename(img_path)}] OCR ì‹œì‘")
        # (1) OCR: ì´ë¯¸ êµ¬í˜„ëœ í•¨ìˆ˜ í˜¸ì¶œ
        output_path, ocr_json = ocr_image_and_save_json_by_extension(img_path)
        # # ë°©ì–´: source_image ê¸°ë³¸ê°’
        # if "source_image" not in ocr_json:
        #     ocr_json["source_image"] = img_path

        # (2) LLM ì¶”ì¶œ + ìœ„ì¹˜ì •ë³´
        data, candidates, selections = extract_with_locations(ocr_json, model_name=st.session_state["model_name"])

        # (3) ì˜¤ë²„ë ˆì´/ì¸ë„¤ì¼ ìƒì„±
        overlay_path = os.path.join(ss["workdir"], "overlay", os.path.basename(img_path) + ".overlay.png")
        os.makedirs(os.path.dirname(overlay_path), exist_ok=True)
        draw_overlays(img_path, selections, overlay_path)

        thumbs_dir = os.path.join(ss["workdir"], "thumbs", os.path.splitext(os.path.basename(img_path))[0])
        os.makedirs(thumbs_dir, exist_ok=True)
        export_thumbnails(img_path, selections, thumbs_dir, margin=0.06)

        # ê²°ê³¼ ì €ì¥
        ss["results"][img_path] = {
            "data": data,
            "candidates": candidates,
            "selections": selections,
            "ocr_json": ocr_json,
        }
        ss["overlay_paths"][img_path] = overlay_path
        ss["thumb_dirs"][img_path] = thumbs_dir
        _log(f"[{os.path.basename(img_path)}] ì²˜ë¦¬ ì™„ë£Œ")

        # except Exception as e:
        #     ss["errors"][img_path] = str(e)
        #     _log(f"[{os.path.basename(img_path)}] ì²˜ë¦¬ ì‹¤íŒ¨: {e}")

        # finally:
            # íì—ì„œ ì œê±°
        if img_path in ss["queue"]:
            ss["queue"].remove(img_path)
        prog.progress(i/n, text=f"ì²˜ë¦¬ ì¤‘... ({i}/{n})")

    prog.empty()

def tab_extract():
    left, right = st.columns([1,2], gap="large")

    with left:
        st.subheader("ì§„í–‰/í")
        total = len(st.session_state["images"])
        done = len(st.session_state["results"])
        waiting = len(st.session_state["queue"])
        st.metric("ì´ ì´ë¯¸ì§€", total)
        st.metric("ì™„ë£Œ", done)
        st.metric("ëŒ€ê¸°", waiting)

        st.divider()
        if st.button("OCR ì²˜ë¦¬ ì‹œì‘", type="primary"):
            _process_queue()

        if st.button("ì‹¤íŒ¨ê±´ ì¬ì‹œë„"):
            for p, msg in list(st.session_state["errors"].items()):
                if p not in st.session_state["queue"] and p not in st.session_state["results"]:
                    st.session_state["queue"].append(p)
            st.success("ì¬ì‹œë„ íì— ë“±ë¡ ì™„ë£Œ")

        st.divider()
        st.subheader("ë¡œê·¸")
        st.text("\n".join(st.session_state["logs"][-200:]))

    with right:
        # st.subheader("íŒŒì´í”„ë¼ì¸ ë‹¨ê³„ ì²´í¬")
#         st.markdown("""
# - âœ… Preprocess (ì˜µì…˜ ì „ë‹¬)
# - âœ… OCR (ì™¸ë¶€ í•¨ìˆ˜ í˜¸ì¶œ)
# - âœ… LLM Extract (extract_with_locations)
# - âœ… Postprocess (ì‚¬í›„ê²€ì¦Â·ì •ê·œí™”)
# - âœ… Validate (í•„ìˆ˜ í•„ë“œ í™•ì¸)
#         """.strip())

        # í˜„ì¬ ì²˜ë¦¬ ì¤‘ ìƒ˜í”Œ(ìµœê·¼ ì™„ë£Œ íŒŒì¼)
        if st.session_state["results"]:
            last_img = list(st.session_state["results"].keys())[-1]
            sample = st.session_state["results"][last_img]["data"]
            st.markdown("#### ìµœê·¼ ê²°ê³¼ ìƒ˜í”Œ (ìƒìœ„ 5~7 í‚¤)")
            preview = {
                "file": os.path.basename(last_img),
                "ë‚ ì§œ": _first_val(sample.get("ë‚ ì§œ", [])),
                "ê±°ë˜ì²˜": _first_val(sample.get("ê±°ë˜ì²˜", [])),
                "ê¸ˆì•¡": _first_val(sample.get("ê¸ˆì•¡", [])),
                "ìœ í˜•": ", ".join(sample.get("ìœ í˜•", [])),
                "ì‚¬ì—…ìë“±ë¡ë²ˆí˜¸": _first_val(sample.get("ì‚¬ì—…ìë“±ë¡ë²ˆí˜¸", [])),
                "ëŒ€í‘œì": _first_val(sample.get("ëŒ€í‘œì", [])),
                "ì£¼ì†Œ": _first_val(sample.get("ì£¼ì†Œ", [])),
            }
            st.json(preview)
            # if st.button("Review ë‹¨ê³„ë¡œ ì§„í–‰ ì•ˆë‚´", type="primary"):
            st.success("ì¶”ì¶œì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ìƒë‹¨ íƒ­ **3. Review**ë¥¼ í´ë¦­í•´ ë°ì´í„°ë¥¼ ê²€í† /ìˆ˜ì •í•˜ì„¸ìš”.")
            st.toast("ë‹¤ìŒ ë‹¨ê³„: Review íƒ­ì—ì„œ ë°ì´í„° ê²€í† ")
        else:
            st.info("ì•„ì§ ì™„ë£Œëœ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

# ========================= Review íƒ­ =========================
def _build_review_table() -> pd.DataFrame:
    """results â†’ í¸ì§‘ ê°€ëŠ¥í•œ í‘œë¡œ êµ¬ì„±"""
    rows = []
    for p, res in st.session_state["results"].items():
        d = res["data"]
        rows.append({
            "file_id": os.path.basename(p),
            "path": p,
            "vendor": _first_val(d.get("ê±°ë˜ì²˜", [])),
            "biz_no": _first_val(d.get("ì‚¬ì—…ìë“±ë¡ë²ˆí˜¸", [])),
            "date": _first_val(d.get("ë‚ ì§œ", [])),
            "amount": _first_val(d.get("ê¸ˆì•¡", [])),
            "category": ", ".join(d.get("ìœ í˜•", [])),
            "representative": _first_val(d.get("ëŒ€í‘œì", [])),
            "address": _first_val(d.get("ì£¼ì†Œ", [])),
            "confidence": "",  # í•„ìš” ì‹œ ì¶”ì •ì¹˜/í›„ë³´ ì ìˆ˜ ë„£ê¸°
            "issues": "",      # ìœ íš¨ì„± ì‹¤íŒ¨ ìš”ì•½
        })
    df = pd.DataFrame(rows)
    # ê°„ë‹¨ ìœ íš¨ì„± í‘œì‹œ
    warn = []
    for i, r in df.iterrows():
        msg = []
        # ì‚¬ì—…ìë²ˆí˜¸ 10ìë¦¬ ì—¬ë¶€
        digits = "".join([c for c in str(r["biz_no"]) if c.isdigit()])
        if digits and len(digits) != 10:
            msg.append("ì‚¬ì—…ìë²ˆí˜¸ í˜•ì‹")
        # ë‚ ì§œ YYYY-MM-DD ì¶”ì •
        if r["date"] and not pd.to_datetime(str(r["date"]), errors="coerce"):
            msg.append("ë‚ ì§œ í˜•ì‹")
        # ê¸ˆì•¡ ìˆ«ìì—¬ë¶€
        if _to_number(r["amount"]) is None:
            msg.append("ê¸ˆì•¡ í˜•ì‹")
        warn.append(", ".join(msg))
    df["issues"] = warn
    return df

def tab_review():
    left, right = st.columns([1,2], gap="large")

    with left:
        st.subheader("ë°ì´í„° ì„¸íŠ¸ ì„ íƒ")
        st.caption("í˜„ì¬ëŠ” LLM ë³´ê°• ê²°ê³¼ë§Œ í‘œì‹œí•©ë‹ˆë‹¤. (ì›ë³¸ OCR/ë³‘í•© ê²°ê³¼ ì¶”ê°€ ê°€ëŠ¥)")
        st.session_state["dataset_sel"] = st.selectbox("Dataset", ["LLM Result"], index=0)

        st.divider()
        st.subheader("í’ˆì§ˆ íŒ¨ë„")
        df = st.session_state.get("review_df_cache")
        if df is not None and not df.empty:
            total = len(df)
            bad = (df["issues"] != "").sum()
            st.metric("ì´ í–‰", total)
            st.metric("ìœ íš¨ì„± ê²½ê³ ", bad)
            st.info("ìë™ ìˆ˜ì • ì œì•ˆ í† ê¸€(ë°ëª¨): ì •ê·œì‹/ë£° ê¸°ë°˜ ë³´ì • ë¡œì§ì„ ì—¬ê¸°ì— ì—°ê²° ê°€ëŠ¥")
        else:
            st.info("í‘œê°€ ìƒì„±ë˜ë©´ ìš”ì•½ì´ í‘œì‹œë©ë‹ˆë‹¤.")

        st.divider()
        st.subheader("Visual Link")
        st.caption("ì„ íƒ í–‰ì˜ í•„ë“œë¥¼ Visual Verify íƒ­ì—ì„œ í•˜ì´ë¼ì´íŠ¸í•©ë‹ˆë‹¤.")
        sel_fields = st.multiselect("í•˜ì´ë¼ì´íŠ¸í•  í•„ë“œ", ["vendor","biz_no","date","amount","representative","address"], default=["vendor","amount"])
        if st.button("ì„ íƒ í–‰ â†’ Visual Verify ì´ë™"):
            idxs = st.session_state.get("review_sel_rows", [])
            if idxs:
                idx = idxs[0]
                row = df.iloc[idx]
                # íŒŒì¼/í•„ë“œ ë§¤í•‘
                st.session_state["selected_file_for_visual"] = row["path"]
                # í•„ë“œëª… ë³€í™˜
                mapping = {
                    "vendor":"ê±°ë˜ì²˜","biz_no":"ì‚¬ì—…ìë“±ë¡ë²ˆí˜¸","date":"ë‚ ì§œ",
                    "amount":"ê¸ˆì•¡","representative":"ëŒ€í‘œì","address":"ì£¼ì†Œ",
                }
                st.session_state["selected_fields_for_visual"] = [mapping[x] for x in sel_fields]
                st.session_state["selected_file_for_visual"] = row["path"]
                st.session_state["selected_fields_for_visual"] = [mapping[x] for x in sel_fields]
                st.success("ì„ íƒëœ íŒŒì¼/í•„ë“œê°€ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤. ìƒë‹¨ íƒ­ **5. Visual Verify**ë¥¼ í´ë¦­í•´ í™•ì¸í•˜ì„¸ìš”.")
                st.toast("ë‹¤ìŒ ë‹¨ê³„: Visual Verify íƒ­ìœ¼ë¡œ ì´ë™í•´ì„œ í•˜ì´ë¼ì´íŠ¸ í™•ì¸")
            else:
                st.warning("ë¨¼ì € í–‰ì„ ì„ íƒí•˜ì„¸ìš”.")

    with right:
        st.subheader("3) Review / í¸ì§‘")
        # í‘œ êµ¬ì¶•/ìºì‹œ
        df = _build_review_table()
        st.session_state["review_df_cache"] = df.copy()
        edited = st.data_editor(
            df,
            use_container_width=True,
            num_rows="dynamic",
            hide_index=True,
            key="review_table",
            on_change=None,
            column_config={
                "path": st.column_config.Column(disabled=True),
                "file_id": st.column_config.Column(disabled=True),
                "issues": st.column_config.Column(help="ìœ íš¨ì„± ê²½ê³  ìš”ì•½"),
            }
        )

            # selection_mode="single-row",
        # ì„ íƒëœ í–‰ ì¸ë±ìŠ¤ ì¶”ì¶œ
        sel = st.session_state.get("review_table", {}).get("selection", {})
        st.session_state["review_sel_rows"] = sel.get("rows", [])

        colx, coly = st.columns([1,1])
        with colx:
            if st.button("í…Œì´ë¸” ë³€ê²½ì‚¬í•­ ì ìš©"):
                # í…Œì´ë¸” í¸ì§‘ ë‚´ìš©ì„ resultsì— ë°˜ì˜
                for _, r in edited.iterrows():
                    path = r["path"] 
                    if path not in st.session_state["results"]:
                        continue
                    d = st.session_state["results"][path]["data"]
                    print(d)
                    # í¸ì§‘ê°’ì€ valueë§Œ ê°±ì‹ (source_idëŠ” None ì²˜ë¦¬)
                    def _set(k_json, val_str):
                        d.setdefault(k_json, [])
                        if d[k_json]:
                            d[k_json][0]["value"] = str(val_str)
                            d[k_json][0]["source_id"] = d[k_json][0].get("source_id") or None
                        else:
                            d[k_json] = [{"value": str(val_str), "source_id": None}]
                    _set("ê±°ë˜ì²˜", r["vendor"])
                    _set("ì‚¬ì—…ìë“±ë¡ë²ˆí˜¸", r["biz_no"])
                    _set("ë‚ ì§œ", r["date"])
                    _set("ê¸ˆì•¡", r["amount"])
                    _set("ëŒ€í‘œì", r["representative"])
                    _set("ì£¼ì†Œ", r["address"])
                st.success("ë°˜ì˜ ì™„ë£Œ")

        with coly:
            if st.button("ìœ íš¨ì„± ì¬ê²€ì‚¬"):
                st.session_state["review_df_cache"] = _build_review_table()
                st.info("ê²€ì‚¬ ì™„ë£Œ")

# ========================= Journal Entry íƒ­ =========================
# ê°„ë‹¨ ë§¤í•‘ ì˜ˆì‹œ(í”„ë¡œë•ì…˜ì—ì„œëŠ” ë³„ë„ ì„¤ì •/DB ì—°ê²° ê¶Œì¥)
ACCOUNT_MAP = {
    # category â†’ (debit_account, credit_account)
    # ì‹¤ì œ íšŒì‚¬/í”„ë¡œì íŠ¸ ë§¤í•‘ì— ë§ì¶° ì»¤ìŠ¤í„°ë§ˆì´ì¦ˆí•˜ì„¸ìš”.
    "ê¸°ë³¸": ("ë¹„ìš©(ê¸°íƒ€)", "ë¯¸ì§€ê¸‰ê¸ˆ"),
    "íŒë§¤ëŒ€í–‰ìˆ˜ìˆ˜ë£Œ": ("ìˆ˜ìˆ˜ë£Œë¹„ìš©", "ë¯¸ì§€ê¸‰ê¸ˆ"),
    "ìš´ì†¡ë¹„": ("ìš´ë°˜ë¹„", "ë¯¸ì§€ê¸‰ê¸ˆ"),
    "ì„ì°¨ë£Œ": ("ì„ì°¨ë£Œ", "ë¯¸ì§€ê¸‰ê¸ˆ"),
    "ë¦¬ìŠ¤/ë Œíƒˆ": ("ì„ì°¨ë£Œ", "ë¯¸ì§€ê¸‰ê¸ˆ"),
}

def _build_journal_preview(df_review: pd.DataFrame, vat_rate: float = 0.1) -> pd.DataFrame:
    """
    Review í‘œ â†’ ë¶„ê°œ ë¯¸ë¦¬ë³´ê¸° êµ¬ì„± (ê°„ë‹¨ ë²„ì „)
    - ì°¨ë³€: ì¹´í…Œê³ ë¦¬ë³„ ë¹„ìš©
    - ëŒ€ë³€: ë¯¸ì§€ê¸‰ê¸ˆ (ë˜ëŠ” ì¹´ë“œ/í˜„ê¸ˆ ë“±ìœ¼ë¡œ í™•ì¥ ê°€ëŠ¥)
    - VAT ë³„ë„ ë¼ì¸ ë¯¸ìƒì„±(ê°„ë‹¨í™”). í•„ìš” ì‹œ ê³µê¸‰ê°€/ì„¸ì•¡ ë¶„ë¦¬ ë¡œì§ ì¶”ê°€.
    """
    rows = []
    for _, r in df_review.iterrows():
        amount = _to_number(r["amount"]) or 0.0
        category = str(r.get("category") or "").split(",")[0].strip() or "ê¸°ë³¸"
        debit_acc, credit_acc = ACCOUNT_MAP.get(category, ACCOUNT_MAP["ê¸°ë³¸"])
        rows.append({
            "date": r["date"],
            "account": debit_acc,
            "debit": amount,
            "credit": 0.0,
            "description": f"{r['vendor']} {category}",
            "vendor": r["vendor"],
            "doc_no": r["biz_no"],
            "cost_center": "",
            "project": "",
            "file_id": r["file_id"],
        })
        rows.append({
            "date": r["date"],
            "account": credit_acc,
            "debit": 0.0,
            "credit": amount,
            "description": f"{r['vendor']} {category}",
            "vendor": r["vendor"],
            "doc_no": r["biz_no"],
            "cost_center": "",
            "project": "",
            "file_id": r["file_id"],
        })
    return pd.DataFrame(rows)

def tab_journal_entry():
    left, right = st.columns([1,2], gap="large")

    with left:
        st.subheader("ë§¤í•‘ í”„ë¡œí•„")
        # st.session_state["mapping_profile"] = st.selectbox("Profile", ["Default"], index=0)
        # st.session_state["vat_rate"] = st.number_input("VAT (%)", value=int(st.session_state["vat_rate"]*100), min_value=0, max_value=20, step=1) / 100.0

        st.markdown("**ê·œì¹™ ìš”ì•½ (ì˜ˆì‹œ)**")
        st.write(pd.DataFrame([
            {"ì¡°ê±´":"category=íŒë§¤ëŒ€í–‰ìˆ˜ìˆ˜ë£Œ","ì°¨ë³€":"ìˆ˜ìˆ˜ë£Œë¹„ìš©","ëŒ€ë³€":"ë¯¸ì§€ê¸‰ê¸ˆ"},
            {"ì¡°ê±´":"category=ìš´ì†¡ë¹„","ì°¨ë³€":"ìš´ë°˜ë¹„","ëŒ€ë³€":"ë¯¸ì§€ê¸‰ê¸ˆ"},
            {"ì¡°ê±´":"default","ì°¨ë³€":"ë¹„ìš©(ê¸°íƒ€)","ëŒ€ë³€":"ë¯¸ì§€ê¸‰ê¸ˆ"},
        ]))

    with right:
        st.subheader("4) Journal Entry ë¯¸ë¦¬ë³´ê¸°")
        df_review = st.session_state.get("review_df_cache")
        if df_review is None or df_review.empty:
            st.info("Review íƒ­ì—ì„œ í‘œê°€ ìƒì„±ë˜ë©´ ì—¬ê¸°ì„œ ë¯¸ë¦¬ë³´ê¸°ë¥¼ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            return

        je = _build_journal_preview(df_review, st.session_state["vat_rate"])
        # ì°¨ëŒ€ë³€ í•©ê³„ ê²€ì¦
        total_debit = float(je["debit"].sum())
        total_credit = float(je["credit"].sum())
        ok = abs(total_debit - total_credit) < 1e-6

        st.dataframe(je, use_container_width=True, hide_index=True)
        st.metric("ì°¨ë³€ í•©ê³„", f"{total_debit:,.0f}")
        st.metric("ëŒ€ë³€ í•©ê³„", f"{total_credit:,.0f}")
        if not ok:
            st.error("ì°¨ëŒ€ë³€ í•©ê³„ê°€ 0ì´ ì•„ë‹™ë‹ˆë‹¤. ë§¤í•‘ ê·œì¹™/ê¸ˆì•¡ì„ í™•ì¸í•˜ì„¸ìš”.")
        else:
            st.success("ì°¨ëŒ€ë³€ í•©ê³„ ì¼ì¹˜")

        st.session_state["je_rows_cache"] = je

# ========================= Visual Verify íƒ­ =========================
def _filter_selections(selections: List[Dict[str,Any]], fields: List[str]) -> List[Dict[str,Any]]:
    if not fields:
        return selections
    return [s for s in selections if s.get("field") in fields]

def tab_visual_verify():
    left, right = st.columns([1,2], gap="large")

    with left:
        st.subheader("íŒŒì¼ ë¦¬ìŠ¤íŠ¸ / ì¸ë„¤ì¼")
        imgs = st.session_state["images"]
        if not imgs:
            st.info("ì—…ë¡œë“œëœ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        current = st.selectbox("íŒŒì¼ ì„ íƒ", options=imgs, format_func=lambda p: os.path.basename(p),
                               index=max(0, imgs.index(st.session_state["selected_file_for_visual"]) if st.session_state["selected_file_for_visual"] in imgs else 0))
        st.session_state["selected_file_for_visual"] = current

        # í•„ë“œ í•„í„°
        fields = st.multiselect("ë ˆì´ì–´(í•„ë“œ) í•„í„°", ["ë‚ ì§œ","ê±°ë˜ì²˜","ê¸ˆì•¡","ì‚¬ì—…ìë“±ë¡ë²ˆí˜¸","ëŒ€í‘œì","ì£¼ì†Œ"],
                                default=st.session_state.get("selected_fields_for_visual") or ["ë‚ ì§œ","ê±°ë˜ì²˜","ê¸ˆì•¡"])
        st.session_state["selected_fields_for_visual"] = fields

        # ì¸ë„¤ì¼ ë³´ì—¬ì£¼ê¸°
        tdir = st.session_state["thumb_dirs"].get(current)
        if tdir and os.path.isdir(tdir):
            files = sorted([os.path.join(tdir, f) for f in os.listdir(tdir) if _is_image(f)])
            if files:
                ncol = min(4, len(files))
                cols = st.columns(ncol)
                for i, p in enumerate(files):
                    with cols[i % ncol]:
                        st.image(p, caption=os.path.basename(p), use_container_width=True)

    with right:
        st.subheader("5) ì‹œê° ê²€ì¦")
        cur = st.session_state["selected_file_for_visual"]
        if not cur or cur not in st.session_state["results"]:
            st.info("ì¢Œì¸¡ì—ì„œ íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”.")
            return

        res = st.session_state["results"][cur]
        sels = _filter_selections(res["selections"], fields)

        # ë™ì  ì˜¤ë²„ë ˆì´ ìƒì„± (í•„ë“œ í•„í„° ë°˜ì˜)
        overlay_tmp = os.path.join(st.session_state["workdir"], "overlay_dynamic", os.path.basename(cur) + ".overlay.png")
        os.makedirs(os.path.dirname(overlay_tmp), exist_ok=True)
        draw_overlays(cur, sels, overlay_tmp)

        col1, col2 = st.columns(2)
        with col1:
            st.image(cur, caption="ì›ë³¸", use_container_width=True)
        with col2:
            with open(overlay_tmp, "rb") as f:
                st.image(f.read(), caption="ì˜¤ë²„ë ˆì´(í•„í„° ì ìš©)", use_container_width=True)

        st.markdown("**ì„ íƒ í•­ëª© ìƒì„¸**")
        st.dataframe(pd.DataFrame(sels), use_container_width=True, hide_index=True)

        st.info("ì–‘ë°©í–¥ í•˜ì´ë¼ì´íŠ¸/ì¢Œí‘œ í¸ì§‘ì€ web canvas ê¸°ë°˜ìœ¼ë¡œ í™•ì¥ ê°€ëŠ¥ (Konva.js / streamlit-drawable-canvas).")

# ========================= Export íƒ­ =========================
def tab_export():
    left, right = st.columns([1,2], gap="large")

    with left:
        st.subheader("ë‚´ë³´ë‚´ê¸° ì˜µì…˜")
        fmt = st.multiselect("ë°ì´í„° í¬ë§·", ["CSV","XLSX","JSON"], default=["CSV","JSON"])
        # erp = st.selectbox("ERP í”„ë¦¬ì…‹", ["Generic","SAP","ë”ì¡´","ì˜ë¦¼ì›"], index=0)
        # st.caption("â€» ERP í¬ë§·ì€ ì»¬ëŸ¼/í—¤ë”/ì¸ì½”ë”© ë§¤í•‘ì„ ì ìš©í•´ì•¼ í•©ë‹ˆë‹¤. (ë°ëª¨ì—ì„œëŠ” Genericë§Œ ì¶œë ¥)")

    with right:
        st.subheader("6) Export")
        # Review í‘œ / JE í‘œ ê°€ì ¸ì˜¤ê¸°
        df_review = st.session_state.get("review_df_cache")
        if df_review is None:
            df_review = pd.DataFrame()
        df_je = st.session_state.get("je_rows_cache")
        if df_je is None:
            df_je = pd.DataFrame()

        colx, coly = st.columns([1,1])
        with colx:
            st.markdown("**ì¶”ì¶œ ë°ì´í„° (Review)**")
            st.dataframe(df_review, use_container_width=True, hide_index=True, height=220)
            if not df_review.empty:
                if "CSV" in fmt:
                    st.download_button("Download Extracted (CSV)",
                        data=df_review.to_csv(index=False).encode("utf-8-sig"),
                        file_name="extracted.csv", mime="text/csv")
                if "JSON" in fmt:
                    st.download_button("Download Extracted (JSON)",
                        data=df_review.to_json(orient="records", force_ascii=False).encode("utf-8"),
                        file_name="extracted.json", mime="application/json")
                if "XLSX" in fmt:
                    buf = io.BytesIO()
                    with pd.ExcelWriter(buf, engine="xlsxwriter") as writer:
                        df_review.to_excel(writer, index=False, sheet_name="extracted")
                    st.download_button("Download Extracted (XLSX)",
                        data=buf.getvalue(), file_name="extracted.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
        with coly:
            st.markdown("**Journal Entry ë¯¸ë¦¬ë³´ê¸°**")
            st.dataframe(df_je, use_container_width=True, hide_index=True, height=220)
            if not df_je.empty:
                if "CSV" in fmt:
                    st.download_button("Download JE (CSV)",
                        data=df_je.to_csv(index=False).encode("utf-8-sig"),
                        file_name="journal_entry.csv", mime="text/csv")
                if "JSON" in fmt:
                    st.download_button("Download JE (JSON)",
                        data=df_je.to_json(orient="records", force_ascii=False).encode("utf-8"),
                        file_name="journal_entry.json", mime="application/json")
                if "XLSX" in fmt:
                    buf2 = io.BytesIO()
                    with pd.ExcelWriter(buf2, engine="xlsxwriter") as writer:
                        df_je.to_excel(writer, index=False, sheet_name="JE")
                    st.download_button("Download JE (XLSX)",
                        data=buf2.getvalue(), file_name="journal_entry.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")

        st.divider()
        # ì „ì²´ ì•„ì¹´ì´ë¸Œ (í‘œ + ì›ë³¸ + ì˜¤ë²„ë ˆì´ + ì£¼ì„JSON + ë¡œê·¸)
        if st.button("ëª¨ë“  ê²°ê³¼ ZIP ë‹¤ìš´ë¡œë“œ"):
            bufz = io.BytesIO()
            with zipfile.ZipFile(bufz, "w", zipfile.ZIP_DEFLATED) as z:
                # í‘œ
                if not df_review.empty:
                    z.writestr("extracted.csv", df_review.to_csv(index=False))
                if not df_je.empty:
                    z.writestr("journal_entry.csv", df_je.to_csv(index=False))
                # ë¡œê·¸
                z.writestr("logs.txt", "\n".join(st.session_state["logs"]))
                # ê°œë³„ íŒŒì¼: ì›ë³¸/ì˜¤ë²„ë ˆì´/ê²°ê³¼ JSON/í›„ë³´/ì„ íƒ/ocr_json
                for p, res in st.session_state["results"].items():
                    base = os.path.splitext(os.path.basename(p))[0]
                    # ì›ë³¸
                    if os.path.exists(p):
                        z.write(p, arcname=f"files/{os.path.basename(p)}")
                    # ì˜¤ë²„ë ˆì´
                    ov = st.session_state["overlay_paths"].get(p)
                    if ov and os.path.exists(ov):
                        z.write(ov, arcname=f"overlay/{os.path.basename(ov)}")
                    # JSONë“¤
                    z.writestr(f"results/{base}.data.json", json.dumps(res["data"], ensure_ascii=False, indent=2))
                    z.writestr(f"results/{base}.candidates.json", json.dumps(res["candidates"], ensure_ascii=False, indent=2))
                    z.writestr(f"results/{base}.selections.json", json.dumps(res["selections"], ensure_ascii=False, indent=2))
                    z.writestr(f"results/{base}.ocr.json", json.dumps(res["ocr_json"], ensure_ascii=False, indent=2))
            st.download_button("Download ZIP Package", data=bufz.getvalue(), file_name="receipt_package.zip", mime="application/zip")

# ========================= íƒ­ ë„¤ë¹„ê²Œì´ì…˜ =========================
tabs = st.tabs(["1. Upload", "2. Extract", "3. Review", "4. Journal Entry", "5. Visual Verify", "6. Export"])
with tabs[0]:
    tab_upload()
with tabs[1]:
    tab_extract()
with tabs[2]:
    tab_review()
with tabs[3]:
    tab_journal_entry()
with tabs[4]:
    tab_visual_verify()
with tabs[5]:
    tab_export()


